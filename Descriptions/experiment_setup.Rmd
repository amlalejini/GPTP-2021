---
title: "Selection Scheme Diagnostics: Experimental Setup "
author: "[Jose Guadalupe Hernandez](https://www.google.com/)"
date: "`r Sys.Date()`"
header-includes:
  - \usepackage[ruled,vlined,linesnumbered]{algorithm2e}
output:
  rmdformats::readthedown:
    self_contained: true
    thumbnails: true
    lightbox: true
    gallery: false
    highlight: "kate"
    use_bookdown: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Purpose of This Research

Although it may appear that EAs are the ultimate tool for trying to solve complex problems, there are some limitations and concerns.
A major obstacle when solving difficult, complex problems that EAs must overcome is traversing a difficult problem space or fitness landscape.
It can be hard to conceptualize what the problem space or fitness landscape looks like because many problems are not formulated in a clean mathematical model.
While the ideal goal would be to develop a tool to visualize these complex problems, that may take a while.

One major goal of this research is to introduce a set of diagnostic problems that isolate characteristics that EAs must contend with when solving real world problems.
It would be beneficial to understand what kinds of EAs are good specific problem spaces and fitness landscapes, but that could prove to be difficult because there are a lot of moving parts in an EA.
To untangle the affects that these moving parts might have on an EA's performance, we focus on isolating selection schemes to see the impact they have on performance, in regard to the set of diagnostic problems.
In order to isolate the different selection schemes, we develop a simple candidate solution representation, mutation operator, and problem representation.

The second major goal of this research is to understand the strength and weaknesses of different selection schemes.
This set of diagnostic problems gives us a *profile* for each selection scheme, which will give us insightful information when deciding what algorithm to use for a particular problem.
In turn, this will also give us insight on the nature of the problem being solved by giving us an understanding of the problem space and fitness landscape that the problem possesses.
There are a variety of selection schemes that exist but comparing their effectiveness and robustness is difficult, as many of them use different sets of problems to test the scheme against.
It is difficult to understand an algorithms strengths and weaknesses from these problems, as it is difficult to understand what characteristics the problem space or fitness landscape posses.
Creating these *profiles* will not only give us a better understanding of each selection schemes' strengths and weaknesses, but also save time when deciding what selection scheme to use.
Using the best selection scheme could also speed up the time required to find a satisfactory solution.


# Research Questions

1. How do selection schemes perform on each diagnostic?
2. What stories do the diveristy metrics tell us about each selection scheme?


# Evolutionary Algorithm Parameters

Now we will define the variables, conditionals, and proceedures for the evolutionary runs in this experiment.
The number of generations will determine the stopping criteria for these evolutionary algorihthms, with a maximum of $G=10,000$ generations.
Population size for these experiments will be $N=512$.
Candidate solutions underlying representation will consist of a vectors of doubles.
We also want to select a decent sized population, where the size of the population will not overcompensate the for the selection schemes.

Next we have to define the mutation operators and probabilities.
We decided to only use point mutations on individual doubles within the vector of a candidate solution.
These point mutations will consist of adding offsets to individual doubles taken from a normal distributiion with $\mu=1$ and $\sigma^2=1$.
The probability of an individual double being mutated is set to $0.7\%$ for this project.
This means that for every $100$ traits being considered for mutation, on average we expect $7$ of them to be mutated.

# Diagnostic Parameters

We need to define the number of doubles, or traits, that are going to be in the vector and a target objective.
Let $M$ be the number of traits and $\gamma$ be the target objective.
For this project we are going to set both $M$ and $\gamma$ to $100$.


# Selection Schemes

Below we will describe the different variables, conditionals, and proceedures that need to be determined for every algorithm.
A full more in depth description of these selection schemes can be found [here](https://jgh9094.github.io/Selection-Scheme-Diagnotics-Part-I/Descriptions/selection_literature.html).
We detmine values from a given range for the selection schemes below.

## (μ,λ) Evolutionary Strategy

This algorithm asks us to define the population size ,$\lambda$, and count of top performing solutions, $\mu$.
Here we define $\lambda = 512$ and $\mu$ will be estimated exponentially by powers of $2$.
This gives us the following parameter estimates.

<center>
|       | $2^{0}$ | $2^{1}$ | $2^{2}$ | $2^{3}$ | $2^{4}$ | $2^{5}$ | $2^{6}$ | $2^{7}$ | $2^{8}$ | $2^{9}$ |
|:-----:|---------|:-------:|:-------:|:-------:|---------|---------|---------|---------|---------|---------|
| $\mu$ | 1       |    2    |    4    |    8    | 16      | 32      | 64      | 128     | 256     | 512     |
</center>

It is important to not that at $\mu = 512$ there is no pressure to improve in fitness.
Looking at the other extreme, at $\mu = 1$ there is immense pressure to be the best performing candidate solution.
These parameter estimates allow us to effectivly explore the range between these extremes.

One final proceedure we need to define is how to select parents from the top performing $\mu$ candidate solutions.
Our method for which candidate solutions are selected as parents is similar to [6], where the top $\mu$ performing candidate solutions produce $\frac{\lambda}{\mu}$ offspring.
We will use this method in our experiments.

## Tournament Selection

The tournament size, $t$, is the only variable that needs to be set for this algorithm.
Here we calcuate the tournament size by mutiplying previous percentages by the size of the population.
This gives us the following parameter estimates.

<center>
|     | $2^{0}$ | $2^{1}$ | $2^{2}$ | $2^{3}$ | $2^{4}$ | $2^{5}$ | $2^{6}$ | $2^{7}$ | $2^{8}$ | $2^{9}$ |
|:---:|---------|:-------:|:-------:|:-------:|---------|---------|---------|---------|---------|---------|
| $t$ | 1       |    2    |    4    |    8    | 16      | 32      | 64      | 128     | 256     | 512     |
</center>

It is important to not that at $t = 512$ there is immense pressure to be the best performing candidate solution.
Looking at the other extreme, at $t = 1$ there is no pressure to improve in fitness.
These parameter estimates allow us to effectivly explore the range between these extremes.

**Let $t^*$ be the best performing tournament size on a given diagnostic.**
We will be using $t^*$ in the following algorithms.

## Fitness Sharing

Fitness sharing requires numerous variables to be defined before execution.
In this experiment, candidate solutions will be selected as parents through tournament selection with tournament size $t^*$.
Tournaments will consist on candidate solutions randomly selected from the entire population.
The parameter $\alpha$ will be set to $1$ based on a recomendation from [11].

This algorithm asks us to define additional variables: a distance function between two candidate solutions, similarity function for two candidate solutions, and theshold for dissimilarity.
All these variables give us the pieces needed for tranforming the raw fitness value.
Let $f_i$ be the raw performance and $f'_i$ be the transformed performance from candidate solution $i$.
This transformation is given by the following,

<center>
$f'_i = \frac{f_i}{m_i}$
</center>

Now we will define $m_i$ for this algorithm.

<center>
$$ m_{i} = \sum_{j=1}^{N} sh(d_{ij})$$
</center>


First we need define the similarity function between two candidate solutions.
Let $i,j$ be any two different candidate solution genomes.
For this project it will be defined by the following,

<center>
$$ d_{ij} = || i - j||_2$$
</center>

Because we know that $i,j$ are just vector of doubles, we can just use the Euclidean Distance to measure their genotype distance.
We are now going to define our similarity function.

<center>
$$
sh(d_{ij}) = \left\{
        \begin{array}{ll}
            1 - (\frac{d_{ij}}{\sigma}) & \quad \text{if } d_{ij} < \sigma\\
            0 & \quad \text{otherwise}
        \end{array}
    \right.
$$
</center>

Finally we have to define the threshold for similarity, $\sigma$.
First we calculate the highest possible $d_{ij}$,

<center>
$$max(d_{ij}) = || <\gamma,...,\gamma> - <0,...,0>||_2 = || <100,...,100> - <0,...,0>||_2 = 1000$$
</center>

Using $max(d_{ij})$ we get the following parameter estimates.

<center>
|          | $0\%$ | $1\%$ | $3\%$ | $6\%$ | $12\%$ | $25\%$ | $50\%$ | $100\%$ |
|:--------:|-------|:-----:|:-----:|:-----:|--------|--------|--------|---------|
| $\sigma$ | 0     |   10  |   30  |   60  | 120    | 250    | 500    | 1000    |
</center>

It is important to not that at $\sigma = 0$ there is no pressure to be genetically different.
This is similar to running a standard Tournament selection.
Looking at the other extreme, at $\sigma = 1000$ there is constant pressure to be genetically different.
These parameter estimates allow us to effectivly explore the range between these extremes.

## Novelty Search

This algorithm asks us to define two variables: distance function for two candidate solution performances and number of nearest neighbors.
The method in which in candidate solutions are selected as parents will be through a tournament selection with tournament size $t^*$.
Let $dist(x,y)$ be the function that measures the distance between two candidate solution performances.
This function can be defined by,

<center>
$$dist(x,y) = || x - y ||_2$$
</center>

Let $k \in \mathbb{Z}^+$ be the $k-$nearest neighbors.
We wanted to explore the parameters around $k=15$ because of its use in [8].
These parameter were estimated keeping $k=15$ in mind to explore the region around it.
This give us the parameter estimates,

<center>
|     | $0\%$ | $\approx1\%$ | $\approx3\%$ | $\approx6\%$ | $\approx12\%$ | $25\%$ | $50\%$ | $100\%$ |
|:---:|-------|:------------:|:------------:|:------------:|---------------|--------|--------|---------|
| $k$ | 0     |       1      |       2      |       4      | 8             | 15     | 30     | 60      |
</center>

It is important to not that at $k = 0$ there is to explore new regions of the fitness landscape.
This is similar to running a standard Tournament selection.
Looking at the other extreme, at $k = 60$ there is constant pressure to move away from the $60$ nearest neighbors within the fitness landscape per candidate solution.


## $\epsilon$-Lexicase

The only variable this algorithm asks us to define is the threshold to pass through filters.
For this experiment we look at the maximum threshold used in [9], which is $\epsilon = 10.0$.
We would like to explore the region between the smallest possible $\epsilon$, 0, and the maximum $\epsilon$ value from [9].
This give us the parameter estimates,

<center>
|            | $0\%$ | $1\%$ | $3\%$ | $6\%$ | $12\%$ | $25\%$ | $50\%$ | $100\%$ |
|:----------:|-------|:-----:|:-----:|:-----:|--------|--------|--------|---------|
| $\epsilon$ | 0     |  0.1  |  0.3  |  0.6  | 1.2    | 2.5    | 5.0    | 10.0    |
</center>


## Age-Layered Population Structure (ALPS)

TBD



# Data Gathering & Metrics

Before we discuss the population and individual statistics we are gathering, we must define some parameters.
Let $\tau$ measure the distance between any given organsims' trait and the target objective $\gamma$.
The population before selection will be given by $P$ and the set of parents after selection will be given by $\Pi$.
Both $P,\Pi$ contain candidate solution ids.
$P$ is the set of all candidate solution ids.
$\Pi$ is the set of candidate ids that were selected to produce offspring for the next generation.

We define a trait being succesfully optimized if the distance for the given trait from the target objective $\gamma$ is less than $\tau$.
A candidate solution is considered an optimal solution all of its traits are considered optimized.
Let $f_i$ measure the aggregate performance for all traits for a given candidate solution $i$ and $v$ be a trait for a candidate solution.

$$ f_i = \sum_{v \in i} v$$

Now we can define some data worth tracking.

## Performance Metrics

### Population Level Metrics ~ Across All Candidate Solutions

Below is a list of data we are tracking at the population level.

- Average number of optimized traits
- Maximum number of optimized traits
- Number of unique optimized traits
- Average aggregate performance:
    - $\bar{f_{P}} = \frac{1}{N} \sum_{i=1}^{N} f_i$
- Take over time
  - Number of generations required for all candidate solutions in the population are optimal solutions.

### Individual Level Metrics ~ Best Performing Candidate Solution

This candidate solution is determined by having the best aggregate performance.
Below is a list of data we are tracking from this caldidate solution.

- Number of optimized traits
- Average trait performance
- Aggregate performance

## Diversity Metrics

- Read Emily's Quantifying the tape of life paper for inspiration!
- Diversity data tracked by systematics tracker
- Loss in diversity:
  - The loss in diversity can be measured by dividing the number of unique candidate solution ids in $\Pi$ by the size of the population $P$
    - $\frac{unique(\Pi)}{size(P)}$
  - Per selection event, this will tell us the the proportion of diversity that is lost and how inclusive the algorithm is
- Selection pressure
  - According to the authors in [5], the change of the average fitness of the population due to selection is a reasonable measure for selection intensity
  - Let $\bar{f_P}$ be the average fitness for population $P$, $s_{P}$ be the standard deviation for $P$'s fitnesses, and $\bar{f_{\Pi}}$ be the average fitness of $\Pi$
  - Selection pressure is defined by:
    - $\frac{\bar{f_{\Pi}} - \bar{f_{P}}}{s_{P}}$
- Selection variance
  - The authors in [5] also define a formulation for selection variance
  - Let $s_P$ be the standard deviation for $P$ and $s_{\Pi}$ be the standard deviation for $\Pi$
  - Selection variance is defined by:
    - $\frac{s_P^2}{s_{\Pi}^2}$
- Both selection pressure and variance are taken at every generation



# Citations
1. Hornby, Greg & Globus, Al & Linden, Derek & Lohn, Jason. (2006). Automated Antenna Design with Evolutionary Algorithms. Collection of Technical Papers - Space 2006 Conference. 1. 10.2514/6.2006-7242.
2. K. Deb, A. Pratap, S. Agarwal and T. Meyarivan, "A fast and elitist multiobjective genetic algorithm: NSGA-II," in IEEE Transactions on Evolutionary Computation, vol. 6, no. 2, pp. 182-197, April 2002.
3. Akyazı U., Uyar A.Ş. (2010) Detection of DDoS Attacks via an Artificial Immune System-Inspired Multiobjective Evolutionary Algorithm. In: Di Chio C. et al. (eds) Applications of Evolutionary Computation. EvoApplications 2010. Lecture Notes in Computer Science, vol 6025. Springer, Berlin, Heidelberg
4. P. Guturu and R. Dantu, "An Impatient Evolutionary Algorithm With Probabilistic Tabu Search for Unified Solution of Some NP-Hard Problems in Graph and Set Theory via Clique Finding," in IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics), vol. 38, no. 3, pp. 645-666, June 2008.
5. T. Blickle and L. Thiele, "A Comparison of Selection Schemes Used in Evolutionary Algorithms," in Evolutionary Computation, vol. 4, no. 4, pp. 361-394, Dec. 1996.
6. Sean Luke, 2013, Essentials of Metaheuristics, Lulu, second edition, available for free at http://cs.gmu.edu/~sean/book/metaheuristics/
7. B. Sareni and L. Krahenbuhl, "Fitness sharing and niching methods revisited," in IEEE Transactions on Evolutionary Computation, vol. 2, no. 3, pp. 97-106, Sept. 1998.
8. Lehman, Joel & Stanley, Kenneth. (2008). Exploiting open-endedness to solve problems through the search for novelty. Artificial Life - ALIFE.
9. La Cava, William, Lee Spector, and Kourosh Danai. “Epsilon-Lexicase Selection for Regression.” Proceedings of the 2016 on Genetic and Evolutionary Computation Conference - GECCO  ’16 (2016): n. pag. Crossref. Web.
10. Hornby, Greg. (2006). ALPS: The age-layered population structure for reducing the problem of premature convergence. GECCO 2006 - Genetic and Evolutionary Computation Conference. 1. 10.1145/1143997.1144142.
11. Anikó Ekárt and Sandor Z. Németh. 2000. A Metric for Genetic Programs and Fitness Sharing. In Proceedings of the European Conference on Genetic Programming. Springer-Verlag, Berlin, Heidelberg, 259–270.