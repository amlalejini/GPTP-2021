---
title: "Selection Scheme Diagnostics: Experimental Setup "
author: "[Jose Guadalupe Hernandez](https://www.google.com/)"
date: "`r Sys.Date()`"
header-includes:
  - \usepackage[ruled,vlined,linesnumbered]{algorithm2e}
output:
  rmdformats::readthedown:
    self_contained: true
    thumbnails: true
    lightbox: true
    gallery: false
    highlight: "kate"
    use_bookdown: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Purpose of This Research

Although it may appear that evolutionary algorithms the best tool to solve complex problems, there are some limitations.
A major obstacle when solving difficult, complex problems is traversing the space of all possible candidate solutions and/or fitness landscape.
It can be extremely difficult to conceptualize the space of all possible candidate solutions or fitness landscape.
This is due to problems and candidate solutions not being formulated in a clean mathematical model.

**The goal of this research is to discover characteristics that distinguish the strengths and weaknesses of different evolutionary algorithms.**
These characteristics are represented by a set of diagnostics.
Each diagnostic is inspired from the characteristics real world problems pose against evolutionary algorithms.
After an evolutionary algorithms' performance is recorded across all diagnostics, we have essentially created a *profile* for the algorithm.
This *profile* would give a better understanding of the kinds of problems each evolutionary algorithm is best suited for.

Imagine attempting to solve a complicated problem with an evolutionary algorithm.
One approach is to experiment with numerous evolutionary algorithms and their parameters with the hope that one finds an optimal solution. 
This approach can be very time consuming and there is also no guarantee that a solution would be found. 
These *profiles* give us an alternative approach, where we can create a set of top candidate evolutionary algorithms.
The set of diagnostics will also allow anyone to generate *profiles* for their own evolutionary algorithms as well.


# Purpose of This Project

Evolutionary algorithms are composed of multiple components that interact with one another.
These interactions can make analyzing different evolutionary algorithms difficult.
If we focus on the major components within an evolutionary algorithm, we can still generate *profiles* with meaningful information. 
More information about evolutionary algorithms can be found at [link](https://jgh9094.github.io/Selection-Scheme-Diagnotics-Part-I/Descriptions/selection_literature.html).

**This project focuses on the impact different selection schemes have on an evolutionary algorithms' attempt to solve different diagnostics.**
The diagnostics for this project are meant to imitate problems where the landscapes require exploitation, exploration, building blocks, and conflicting optimization tasks.
*Profiles* generated from these diagnostics provide meaningful information, as these diagnostics are common across multiple problem domains.

Looking through the literature on selection schemes, it is clear that a copious amount of selection schemes exist.
Without getting into the literature too much, it also clear that selection schemes are becoming more complex over time. 
More information about selection schemes can be found at [link](https://jgh9094.github.io/Selection-Scheme-Diagnotics-Part-I/Descriptions/selection_literature.html).
Complications may arise when trying to understand the strengths and weaknesses of a selection scheme. 

Understanding the nature of the problem being solved can be difficult, as it may not be possible to conceptualize the fitness landscape or space of all possible solutions.
This means that knowing the kinds of problems a selection scheme is best suited for may not be possible using this approach.
Fortunately, these diagnostics help mitigate this issue. 
By isolating key characteristics that problems possess, we are able to get a better understanding of each selection schemes' strengths and weaknesses.

Another complication that may arise is understanding and testing different novelties integrated within selection schemes.
Many of the novelties different selection schemes possess may be integrated within other selection schemes as well. 
A framework for selection schemes may give us a better understanding of how this may be possible.
This could open a path up to finding more robust evolutionary algorithms. 
The authors (me) framework for selection schemes can be found at [link](https://jgh9094.github.io/Selection-Scheme-Diagnotics-Part-I/Descriptions/selection_depth.html).

**The goal of this project is to develop a set of diagnostics that generate meaningful *profiles*.**
The *profiles* would give readers information regarding each selection schemes' strengths, weaknesses, and novelties.
Having this information can be the difference between finding an optimal solution and not.


# Project Research Questions

1. How do selection schemes perform on each diagnostic?
2. What do the recorded metrics tell us about each selection scheme?
3. Are there any dominating selection schemes, and why?
4. How do the different novelties compare?


# Evolutionary Algorithm Setup

The variables, conditionals, and procedures for the evolutionary algorithm used in this experiment will be defined in this section.
The number of generations will be used to determine the stopping criteria for these evolutionary algorithms, with a maximum of $G=10,000$ generations.
Population size for these experiments will be $N=512$, and the population candidate solutions is given by $P = \{j_1, ..., j_N\}$.

The underlying representation for candidate solutions will be a vector of doubles.
Each double in the representation will be called a trait from this point on. 
The set of traits representing a candidate solution will be denoted by $T = \{t_1, ..., t_M\}$, where $M \in \mathbb{Z}^+$ denotes the number of traits.
Notice that $T \in \mathbb{R}^{M}$, hence every candidate solution in $P$ comes from $\mathbb{R}^{M}$.
This means that $\forall j \in T$, we can represent $j = \{t_1, ..., t_M \}$.
All traits will be set to $0$ for every candidate solution at the start of the run. 

The mutation operator consists of point mutations on individual traits.
These point mutations add offsets sampled from a normal distribution, with $\mu=0$ and $\sigma^2=1$, to a trait.
It is not possible for a trait to be less than 0.
In the event that a mutation causes a trait to fall below $0$, that trait will be set to $0$.
The probability of a trait becoming mutated is set to $7\%$.
This means that for every $100$ traits being considered for mutation; on average we expect $7$ of them receive a mutation.


# Diagnostic Setup

Candidate solutions are challenged to optimize their traits to some corresponding target objective. 
The number of traits per candidate solution also gives us the number of target objectives.
This means that $M$ is also used to determine the number of target objectives.
From this we get a vector of target objectives $\Gamma = \{\gamma_1, ..., \gamma_M\}$, where $\Gamma \in \mathbb{R}^M$.
Each target objective corresponds to a trait by position, or $\gamma_i \leftrightarrow t_i$.

If a mutation causes a trait to rise above the corresponding target objective, the trait is set to the target objective minus the remaining distance passed the target objective caused by the mutation. 
For example, let trait $t=99$, mutation $m=1.1$, and target objective $\gamma=100$.
The new trait $t'$ is given by,

<center>
$$\begin{align*}
t' &= \gamma - (t + m - \gamma) \\
   &= 100 - (99 + 1.1 - 100) \\ 
   &= 100 - (101.1 - 100) \\
   &= 100 - 0.1 \\
   &= 99.9 \\ 
\end{align*}
$$
</center>

We can see that $t + m - \gamma$ is the remaining distance passed the target objective caused by the mutation.
For this project we are going to set $M$ and every element in $\Gamma$ too $100$. 
This gives us $\Gamma = \{100, .., 100 \}$.


# Selection Schemes

Below we will describe the different variables, conditionals, and procedures that need to be determined for every selection scheme.
A full more in depth description of these selection schemes used in this project can be found [here](https://jgh9094.github.io/Selection-Scheme-Diagnotics-Part-I/Descriptions/selection_literature.html).

## (μ,λ) Evolutionary Strategy

This algorithm asks requires users to define the population size $\lambda$ and count of top performing solutions $\mu$.
Here we set $\lambda = 512$ and estimate $\mu$ exponentially by powers of two.
This gives us the following parameter estimates.

<center>
|       | $2^{0}$ | $2^{1}$ | $2^{2}$ | $2^{3}$ | $2^{4}$ | $2^{5}$ | $2^{6}$ | $2^{7}$ | $2^{8}$ | $2^{9}$ |
|:-----:|---------|:-------:|:-------:|:-------:|---------|---------|---------|---------|---------|---------|
| $\mu$ | 1       |    2    |    4    |    8    | 16      | 32      | 64      | 128     | 256     | 512     |
</center>

It is important to note that at $\mu = 512$ there is no pressure to improve in fitness.
Looking at the other extreme, at $\mu = 1$ there is immense pressure to be the best performing candidate solution.
These parameter estimates allow us to effectively explore the range between these extremes.

One final procedure we need to define is how to select parents from the top performing $\mu$ candidate solutions.
Our method for which candidate solutions are selected as parents is similar to [6], where the top $\mu$ performing candidate solutions produce $\frac{\lambda}{\mu}$ offspring.
In the event of ties occurring, we randomly select one of the top performing candidate solutions until the $\mu$ requirement is met.

## Tournament Selection

Tournament size $t$ is the only parameter that needs to be set for this algorithm.
Here tournament size is estimated exponentially by powers of two. 
This gives us the following parameter estimates.

<center>
|     | $2^{0}$ | $2^{1}$ | $2^{2}$ | $2^{3}$ | $2^{4}$ | $2^{5}$ | $2^{6}$ | $2^{7}$ | $2^{8}$ | $2^{9}$ |
|:---:|---------|:-------:|:-------:|:-------:|---------|---------|---------|---------|---------|---------|
| $t$ | 1       |    2    |    4    |    8    | 16      | 32      | 64      | 128     | 256     | 512     |
</center>

It is important to note that at $t = 512$ there is immense pressure to be the best performing candidate solution.
Looking at the other extreme, at $t = 1$ there is no pressure to improve in fitness.
These parameter estimates allow us to effectively explore the range between these extremes.

**Let $t^*$ be the best performing tournament size on a given diagnostic.**
We will be using $t^*$ in the following algorithms.

## Fitness Sharing

Fitness sharing requires multiple parameters and functions to be defined prior to running.
In this experiment, candidate solutions will be selected as parents through tournament selection with tournament size $t^*$.
Tournaments will consist of candidate solutions randomly selected from the entire population.
The parameter $\alpha$ will be set to $1$ based on a recommendation from [11].

This algorithm also asks us to define a function measuring distance between two candidate solutions, function measuring similarity between two candidate solutions, and threshold for dissimilarity.
All these pieces give us the ability to transform the original fitness value.
Let $f_i$ be the original fitness value and $f'_i$ be the transformed fitness value for candidate solution $i$.
This transformation is given by the following,

<center>
$f'_i = \frac{f_i}{m_i}$
</center>

Now we will define $m_i$ for this algorithm.

<center>
$$ m_{i} = \sum_{j=1}^{N} sh(d_{ij})$$
</center>


First, we need define the similarity function between two candidate solutions.
Let $i,j$ be any two different candidate solutions.
For this project it will be defined by the following,

<center>
$$ d_{ij} = || i - j||_2$$
</center>

Because we know that $i,j$ are just vector of doubles, we can just use the Euclidean Distance to measure their distance in $\mathbb{R}^M$.
We are now going to define our similarity function.

<center>
$$
sh(d_{ij}) = \left\{
        \begin{array}{ll}
            1 - (\frac{d_{ij}}{\sigma}) & \quad \text{if } d_{ij} < \sigma\\
            0 & \quad \text{otherwise}
        \end{array}
    \right.
$$
</center>

Finally, we have to define the threshold for similarity, $\sigma$.
First, we calculate the highest possible $d_{ij}$,

<center>
$$max(d_{ij}) = || <\gamma_1,...,\gamma_M> - <0,...,0>||_2 = || <100,...,100> - <0,...,0>||_2 = 1000$$
</center>

Using $max(d_{ij})$ we get the following parameter estimates.

<center>
|          | $0\%$ | $1\%$ | $3\%$ | $6\%$ | $12\%$ | $25\%$ | $50\%$ | $100\%$ |
|:--------:|-------|:-----:|:-----:|:-----:|--------|--------|--------|---------|
| $\sigma$ | 0     |   10  |   30  |   60  | 120    | 250    | 500    | 1000    |
</center>

It is important to note that at $\sigma = 0$ there is no pressure to be genetically different.
This is similar to running a standard tournament selection.
Looking at the other extreme, at $\sigma = 1000$ there is constant pressure to be genetically different.
These parameter estimates allow us to effectively explore the range between these extremes.

## Novelty Search

This algorithm requires a function measuring distance between two candidate solution performances and number of nearest neighbors.
The method in which candidate solutions are selected as parents will be through tournament selection with tournament size $t^*$.
Let $dist(x,y)$ be the function that measures the distance between two candidate solution performances.
This function can be defined by,

<center>
$$dist(x,y) = | x - y |$$
</center>

Let $k \in \mathbb{Z}^+$ be the $k-$nearest neighbors.
We wanted to explore the parameters around $k=15$ because of its use in [8].
These parameters were estimated keeping $k=15$ in mind to explore the region around it.
This give us the parameter estimates,

<center>
|     | $0\%$ | $\approx1\%$ | $\approx3\%$ | $\approx6\%$ | $\approx12\%$ | $25\%$ | $50\%$ | $100\%$ |
|:---:|-------|:------------:|:------------:|:------------:|---------------|--------|--------|---------|
| $k$ | 0     |       1      |       2      |       4      | 8             | 15     | 30     | 60      |
</center>

It is important to note that at $k = 0$ there is no pressure for solutions to increase their distance from neighbors on the fitness landscape.
This is similar to running a standard tournament selection.
Looking at the other extreme, at $k = 60$ there is constant pressure to move away from the $60$ nearest neighbors within the fitness landscape per candidate solution.


## ϵ-Lexicase

This algorithm requires a threshold $\epsilon$ for differences in performance.
The maximum threshold used in [9] will be used to estimate other threshold values, where $\epsilon = 10.0$.
We would like to explore the region between the smallest possible $\epsilon$ and the maximum $\epsilon$ value from [9].
This give us the parameter estimates,

<center>
|            | $0\%$ | $1\%$ | $3\%$ | $6\%$ | $12\%$ | $25\%$ | $50\%$ | $100\%$ |
|:----------:|-------|:-----:|:-----:|:-----:|--------|--------|--------|---------|
| $\epsilon$ | 0     |  0.1  |  0.3  |  0.6  | 1.2    | 2.5    | 5.0    | 10.0    |
</center>

It is important to note that $\epsilon = 0$ gives us the original lexicase selection. 


## Age-Layered Population Structure (ALPS)

TBD

# Diagnostics

TODO - Describes the set up for for diagnostics. Follow simialr flow to selection depth and experiement set up

TODO - Create diagnostic depth


# Data Gathering & Metrics

Before discussing the statistics being gathered, we must define some variables.
Let $\tau$ be a threshold for distance between a trait and its corresponding target objective.
The current population of candidate solutions is given by $P$.
A candidate solution's trait performance will be called fitness.
The set of fitnesses for a candidate solution will be denoted by $F = \{f_1,...,f_m\}$. 
Each fitness value corresponds to a traits' performance by position, or $f_i \leftrightarrow t_i$. 

Traits are considered optimal if the distance from the trait to the corresponding target objective is less than $\tau$.
Let $t \in \mathbb{R}$ be some trait, $\gamma \in \mathbb{R}$ be the corresponding target objective, and the function $op$ determine optimality. 

The function $op$ is described by,
$$
op(t, \gamma) = \left\{
        \begin{array}{ll}
            1 & \quad \text{if } | t - \gamma | \leq \tau\\
            0 & \quad \text{otherwise}
        \end{array}
    \right.
$$


A candidate solution is considered optimal if all of its traits are optimal.
From this definition we derive the following definition.

Let $j = \{t_1, ..., t_M \}$ be a candidate solution from $P$, where $j \in \mathbb{R}^M$.
If $j$ is an optimal solution for some set of target objectives $\Gamma = \{\gamma_1, ..., \gamma_M \}$, then 
$$ M = \sum_{i = 1}^{M} op(t_i, \gamma_i)$$

We would like to note that different values of $\tau$ will be explored to find interesting results. 


## Performance Metrics

Below we describe the data we are tracking at different levels that give us insight on performance.

### Individual Candidate Solution Metrics

These metrics are data we are collecting at the individual level. 

#### Number of Optimized Traits

To obtain the number of optimized traits for a candidate solution, we must go through every trait and determine its optimality.
After doing this, we can count the number of optimized traits.

Let $c$ denote the number of optimized traits for candidate solution $j= \{t_1, ..., t_M \}$, where $c \in \mathbb{N}$.
For some given set of target objectives $\Gamma = \{ \gamma_1, ..., \gamma_M \}$, the number of optimized traits for $j$ is given by

$$c = \sum_{i = 1}^{M} op(t_i, \gamma_i) $$


#### Fitness Aggregate and Average Trait Fitness

All diagnostics can be thought of as maximization problems with different constraints applied.
Each diagnostic will measure trait performance differently, giving us different performances for the same candidate solution.
We will let $\omega$ denote the aggregate of fitnesses for a candidate solution. 

For candidate solution $j$, let $F_j = \{f_1, ..., f_m \}$ represent its fitness vector, where $F_j \in \mathbb{R}^M$. 
Now let $\omega$ denote the aggregate of fitnesses for a candidate solution $j$.

We define $\omega$ by, 
$$ \omega = \sum_{f \in F_j} f$$

To calculate average trait fitness, we do the following, 

$${\bar{\omega}} = \frac{\omega}{M} =  \frac{1}{M} \sum_{f \in F_j} f$$


### Population Metrics Across All Candidate Solutions

These metrics calculated across all candidate solutions in the population.
Let $P_{F}$ be the set of aggregate fitnesses and $P_{C}$ be the set of optimized traits counts, both per candidate solution in the population $P$.


#### Average Number of Optimized Traits

The average number of optimized traits is calculated by summing up every candidate solutions' optimized trait count, followed by dividing the sum by the size of the population.
This data gives us insight on the average number of traits a candidate solution in the population can maintain optimized. 
Now let $C_P$ represent the average number of optimized traits. 

We define $C_P$ by, 
$$C_P = \frac{1}{N} \sum_{c \in P_C} c$$


#### Maximum Number of Optimized Traits

We go through every candidate solutions' optimized trait count and record the maximum.
Now let $C_{max}$ represent the maximum optimized trait count. 

We define $C_{max}$ by, 
$$C_{max} = max\{P_C \}$$

#### Number of Unique Optimized Traits

We go through each target objective in $\Gamma$, and see if there exists a candidate solution that has the corresponding trait optimized.
This will tell us the spread of optimized traits that a population can maintain. 
Now let $C_{uni}$ represent the number of unique optimized traits. 

For some set of target objectives $\Gamma = \{\gamma_1, ..., \gamma_M\}$, we define $C_{uni}$ by,

$$C_{uni} = \sum_{i = 1}^{M} OP(\gamma_i)$$
Where the function $OP$ measures whether or not a candidate solution exists with an optimized trait for the corresponding target objective.

We define $OP$ by,
$$
OP(\gamma_i) = \left\{
        \begin{array}{ll}
            1 & \quad \text{if there exists a solution with trait } t_i \text{, where } op(t_i, \gamma_i) = 1\\
            0 & \quad \text{otherwise}
        \end{array}
    \right.
$$

#### Fitness Aggregate Average

We sum every candidate solution aggregate fitness value $\omega$, followed by dividing the sum by the size of the population. 
Now let $\bar{f_{P}}$ represent the average aggregate fitness per candidate solution. 

We define $\bar{f_{P}}$ by, 
$$\bar{f_{P}} = \frac{1}{N} \sum_{f \in P_F} f$$

#### Optimal Solutions Found Per Generation

We record the number of optimal solutions per generation. 

### Candidate Solutions of Interest

Below we describe different kinds of candidate solutions we are interested in analyzing.

#### Maximum Performing Candidate Solution

This candidate solution is selected because their aggregate fitness value $\omega = max\{P_F\}$.
In the event of a tie we select the candidate solution with the most optimized traits. 
If ties still occur, we randomly select a candidate solution.
Below is a list of data we are gathering for these kinds of solutions. 

- [Number of Optimized Traits](#number-of-optimized-traits)
- [Fitness Aggregate and Average Trait Fitness](#fitness-aggregate-and-average-trait-fitness)

#### Maximum Optimized Trait Count

This candidate solution is selected because their aggregate fitness value $c = C_{max}$.
In the event of a tie we select the candidate solution with the maximum aggregate fitness value. 
If ties still occur, we randomly select a candidate solution.
Below is a list of data we are gathering for these kinds of solutions. 

- [Number of Optimized Traits](#number-of-optimized-traits)
- [Fitness Aggregate and Average Trait Fitness](#fitness-aggregate-and-average-trait-fitness)

#### Most Common Candidate Solution

This candidate solution is selection because it is the most common solution genotype in the population.
In the event of ties, we first filter solutions by the maximum aggregate fitness value, then by maximum number of optimized traits.
If ties still occur, we randomly select a candidate solution. 
Below is a list of data we are gathering for these kinds of solutions. 

- [Number of Optimized Traits](#number-of-optimized-traits)
- [Fitness Aggregate and Average Trait Fitness](#fitness-aggregate-and-average-trait-fitness)


## Diversity Metrics

These metrics are all population based as well, but with a focus on diversity.
Let $\Pi$ be the set of candidate solutions selected to produce an offspring.
We want to note that $\Pi$ consists of candidate solutions from population $P$.
Also, let $P_F$ be the set of aggregate fitnesses per candidate solution in the population P.


### Systematics Tracker Data

I need to look into the kinds of data that the systematic tracker can record. 
I know that it does phylogenies, but need to do more looking into. 

### Loss in diversity

The loss in diversity can be measured by dividing the number of unique candidate solutions selected to produce an offspring by the size of the population. 
Per selection event, this will tell us the proportion of diversity that is lost and how inclusive the algorithm is. 

Loss in diversity can now be defined by,

$$ \frac{unique(\Pi)}{N}$$

### Selection Pressure

According to the authors in [5], the change of the average fitness of the population due to selection is a reasonable measure for selection intensity.
Let $\bar{f_P}$ be the average and $s_P$ be the standard deviation of the set of all aggregate fitnesses $P_F$.
Also let $\bar{f_\Pi}$ measure a value similar to $\bar{f_P}$, but with respect to $\Pi$.
Selection pressure can now be defined by, 
$$\frac{\bar{f_{\Pi}} - \bar{f_{P}}}{s_{P}}$$

### Selection Variance

The authors in [5] also define a measurement for selection variance. 
Before we define this, let $\Pi_F$ denote the set of aggregate fitnesses for candidate solutions in $\Pi$. 
Now let $s_P$ be the standard deviation for $P_F$ and $s_{\Pi}$ be the standard deviation for $\Pi_F$.
Selection variance can now be defined by,

$$\frac{s_P^2}{s_{\Pi}^2}$$

**Both selection pressure and variance are taken at every generation**


# Citations
1. Hornby, Greg & Globus, Al & Linden, Derek & Lohn, Jason. (2006). Automated Antenna Design with Evolutionary Algorithms. Collection of Technical Papers - Space 2006 Conference. 1. 10.2514/6.2006-7242.
2. K. Deb, A. Pratap, S. Agarwal and T. Meyarivan, "A fast and elitist multiobjective genetic algorithm: NSGA-II," in IEEE Transactions on Evolutionary Computation, vol. 6, no. 2, pp. 182-197, April 2002.
3. Akyazı U., Uyar A.Ş. (2010) Detection of DDoS Attacks via an Artificial Immune System-Inspired Multiobjective Evolutionary Algorithm. In: Di Chio C. et al. (eds) Applications of Evolutionary Computation. EvoApplications 2010. Lecture Notes in Computer Science, vol 6025. Springer, Berlin, Heidelberg
4. P. Guturu and R. Dantu, "An Impatient Evolutionary Algorithm With Probabilistic Tabu Search for Unified Solution of Some NP-Hard Problems in Graph and Set Theory via Clique Finding," in IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics), vol. 38, no. 3, pp. 645-666, June 2008.
5. T. Blickle and L. Thiele, "A Comparison of Selection Schemes Used in Evolutionary Algorithms," in Evolutionary Computation, vol. 4, no. 4, pp. 361-394, Dec. 1996.
6. Sean Luke, 2013, Essentials of Metaheuristics, Lulu, second edition, available for free at http://cs.gmu.edu/~sean/book/metaheuristics/
7. B. Sareni and L. Krahenbuhl, "Fitness sharing and niching methods revisited," in IEEE Transactions on Evolutionary Computation, vol. 2, no. 3, pp. 97-106, Sept. 1998.
8. Lehman, Joel & Stanley, Kenneth. (2008). Exploiting open-endedness to solve problems through the search for novelty. Artificial Life - ALIFE.
9. La Cava, William, Lee Spector, and Kourosh Danai. “Epsilon-Lexicase Selection for Regression.” Proceedings of the 2016 on Genetic and Evolutionary Computation Conference - GECCO  ’16 (2016): n. pag. Crossref. Web.
10. Hornby, Greg. (2006). ALPS: The age-layered population structure for reducing the problem of premature convergence. GECCO 2006 - Genetic and Evolutionary Computation Conference. 1. 10.1145/1143997.1144142.
11. Anikó Ekárt and Sandor Z. Németh. 2000. A Metric for Genetic Programs and Fitness Sharing. In Proceedings of the European Conference on Genetic Programming. Springer-Verlag, Berlin, Heidelberg, 259–270.