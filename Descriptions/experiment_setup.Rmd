---
title: "Selection Scheme Diagnostics: Experimental Setup "
author: "[Jose Guadalupe Hernandez](https://www.google.com/)"
date: "`r Sys.Date()`"
header-includes:
  - \usepackage[ruled,vlined,linesnumbered]{algorithm2e}
output:
  rmdformats::readthedown:
    self_contained: true
    thumbnails: true
    lightbox: true
    gallery: false
    highlight: "kate"
    use_bookdown: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Purpose of This Research

Although it may appear that EAs are the ultimate tool for trying to solve complex problems, there are some limitations and concerns.
A major obstacle when solving difficult, complex problems that EAs must overcome is traversing a difficult problem space or fitness landscape.
It can be hard to conceptualize what the problem space or fitness landscape looks like because many problems are not formulated in a clean mathematical model.
While the ideal goal would be to develop a tool to visualize these complex problems, that may take a while.

One major goal of this research is to introduce a set of diagnostic problems that isolate characteristics that EAs must contend with when solving real world problems.
It would be beneficial to understand what kinds of EAs are good specific problem spaces and fitness landscapes, but that could prove to be difficult because there are a lot of moving parts in an EA.
To untangle the affects that these moving parts might have on an EA's performance, we focus on isolating selection schemes to see the impact they have on performance, in regard to the set of diagnostic problems.
In order to isolate the different selection schemes, we develop a simple candidate solution representation, mutation operator, and problem representation.

The second major goal of this research is to understand the strength and weaknesses of different selection schemes.
This set of diagnostic problems gives us a *profile* for each selection scheme, which will give us insightful information when deciding what algorithm to use for a particular problem.
In turn, this will also give us insight on the nature of the problem being solved by giving us an understanding of the problem space and fitness landscape that the problem possesses.
There are a variety of selection schemes that exist but comparing their effectiveness and robustness is difficult, as many of them use different sets of problems to test the scheme against.
It is difficult to understand an algorithms strengths and weaknesses from these problems, as it is difficult to understand what characteristics the problem space or fitness landscape posses.
Creating these *profiles* will not only give us a better understanding of each selection schemes' strengths and weaknesses, but also save time when deciding what selection scheme to use.
Using the best selection scheme could also speed up the time required to find a satisfactory solution.


# Research Questions

1. How do selection schemes perform on each diagnostic?
2. What do the recorded metrics tell us about each selection scheme?


# Evolutionary Algorithm Setup

Now we will define the variables, conditionals, and proceedures for the evolutionary runs in this experiment.
The number of generations will determine the stopping criteria for these evolutionary algorihthms, with a maximum of $G=10,000$ generations.
Population size for these experiments will be $N=512$, and the population is given by $P = \{j_1, ..., j_N\}$.
We want to select a decent sized population, where the size of the population will not overcompensate the for the selection schemes.

Next we have to define the underlying representation for the candidate solutions. 
The underlying representation for candidate solutions will be a vector of doubles.
Each double in the representation will be called a trait from this point on. 
The set of traits a candidate solution has will be denoted by $T = \{t_1, ..., t_M\}$, where $M \in \mathbb{Z}^+$ denotes the number of traits desired.
We can see that $T \in \mathbb{R}^{M}$, hence every candidate solution in $P$ comes from $\mathbb{R}^{M}$. 
All traits will be set to $0$ for every candidate solution at the start of the run. 

The mutation operators consists of point mutations on individual traits.
These point mutations add offsets sampled from a normal distributiion, with $\mu=0$ and $\sigma^2=1$, to the trait.
It is not possible for a trait to be less than 0.
In the event that a mutation causes a trait to fall below $0$, that trait will be set to $0$.
The probability of a trait becoming mutated is set to $7\%$.
This means that for every $100$ traits being considered for mutation, on average we expect $7$ of them to be mutated.

# Diagnostic Setup

Candidate solutions are challenged to optimize their traits to some corresponding target objective. 
The number of traits per candidate solution also gives us the number of target objectives.
This means that $M$ is also used to determine the number of target objectives.
From this we get a vector of target objectives $\Gamma = \{\gamma_1, ..., \gamma_M\}$, where $\Gamma \in \mathbb{R}^M$.
Each target objective corresponds to a trait by position, or $\gamma_i \leftrightarrow t_i$.

If a mutation causes a trait to rise above the corresponding target objective, the trait is set to the target objective minus the remaining distance passed the target objective. 
For example, let trait $t=99$, mutation $m=1.1$, and target objective $\gamma=100$.
The new trait $t'$ is given by,

$$\begin{align*}
t' &= \gamma - (t + m - \gamma) \\
   &= 100 - (99 + 1.1 - 100) \\ 
   &= 100 - (101.1 - 100) \\
   &= 100 - 0.1 \\
   &= 99.9 \\ 
\end{align*}
$$

We can see that $t + m - \gamma$ is the remaining distance passed the target objective.
For this project we are going to set $M$ and every element in $\Gamma$ too $100$. 
This gives us $\Gamma = \{100, .., 100 \}$.


# Selection Schemes

Below we will describe the different variables, conditionals, and proceedures that need to be determined for every algorithm.
A full more in depth description of these selection schemes can be found [here](https://jgh9094.github.io/Selection-Scheme-Diagnotics-Part-I/Descriptions/selection_literature.html).
We detmine variables, conditionals, and proceedures for the selection schemes used in this experiment.

## (μ,λ) Evolutionary Strategy

This algorithm asks us to define the population size ,$\lambda$, and count of top performing solutions, $\mu$.
Here we estimate $\lambda = 512$ and $\mu$ will be estimated exponentially by powers of two.
This gives us the following parameter estimates.

<center>
|       | $2^{0}$ | $2^{1}$ | $2^{2}$ | $2^{3}$ | $2^{4}$ | $2^{5}$ | $2^{6}$ | $2^{7}$ | $2^{8}$ | $2^{9}$ |
|:-----:|---------|:-------:|:-------:|:-------:|---------|---------|---------|---------|---------|---------|
| $\mu$ | 1       |    2    |    4    |    8    | 16      | 32      | 64      | 128     | 256     | 512     |
</center>

It is important to note that at $\mu = 512$ there is no pressure to improve in fitness.
Looking at the other extreme, at $\mu = 1$ there is immense pressure to be the best performing candidate solution.
These parameter estimates allow us to effectivly explore the range between these extremes.

One final proceedure we need to define is how to select parents from the top performing $\mu$ candidate solutions.
Our method for which candidate solutions are selected as parents is similar to [6], where the top $\mu$ performing candidate solutions produce $\frac{\lambda}{\mu}$ offspring.
In the event of ties occuring, we randomly select one of the top performing candidate solutions until the $\mu$ requirement is met.

## Tournament Selection

Tournament size $t$ is the only variable that needs to be set for this algorithm.
Here estimate tournament size by powers of two. 
This gives us the following parameter estimates.

<center>
|     | $2^{0}$ | $2^{1}$ | $2^{2}$ | $2^{3}$ | $2^{4}$ | $2^{5}$ | $2^{6}$ | $2^{7}$ | $2^{8}$ | $2^{9}$ |
|:---:|---------|:-------:|:-------:|:-------:|---------|---------|---------|---------|---------|---------|
| $t$ | 1       |    2    |    4    |    8    | 16      | 32      | 64      | 128     | 256     | 512     |
</center>

It is important to not that at $t = 512$ there is immense pressure to be the best performing candidate solution.
Looking at the other extreme, at $t = 1$ there is no pressure to improve in fitness.
These parameter estimates allow us to effectivly explore the range between these extremes.

**Let $t^*$ be the best performing tournament size on a given diagnostic.**
We will be using $t^*$ in the following algorithms.

## Fitness Sharing

Fitness sharing requires numerous variables to be defined before execution.
In this experiment, candidate solutions will be selected as parents through tournament selection with tournament size $t^*$.
Tournaments will consist on candidate solutions randomly selected from the entire population.
The parameter $\alpha$ will be set to $1$ based on a recomendation from [11].

This algorithm asks us to define additional variables: a distance function between two candidate solutions, similarity function for two candidate solutions, and theshold for dissimilarity.
All these variables give us the pieces needed for tranforming the raw performance fitness value.
Let $f_i$ be the raw performance and $f'_i$ be the transformed performance from candidate solution $i$.
This transformation is given by the following,

<center>
$f'_i = \frac{f_i}{m_i}$
</center>

Now we will define $m_i$ for this algorithm.

<center>
$$ m_{i} = \sum_{j=1}^{N} sh(d_{ij})$$
</center>


First we need define the similarity function between two candidate solutions.
Let $i,j$ be any two different candidate solution genomes.
For this project it will be defined by the following,

<center>
$$ d_{ij} = || i - j||_2$$
</center>

Because we know that $i,j$ are just vector of doubles, we can just use the Euclidean Distance to measure their genotype distance.
We are now going to define our similarity function.

<center>
$$
sh(d_{ij}) = \left\{
        \begin{array}{ll}
            1 - (\frac{d_{ij}}{\sigma}) & \quad \text{if } d_{ij} < \sigma\\
            0 & \quad \text{otherwise}
        \end{array}
    \right.
$$
</center>

Finally we have to define the threshold for similarity, $\sigma$.
First we calculate the highest possible $d_{ij}$,

<center>
$$max(d_{ij}) = || <\gamma,...,\gamma> - <0,...,0>||_2 = || <100,...,100> - <0,...,0>||_2 = 1000$$
</center>

Using $max(d_{ij})$ we get the following parameter estimates.

<center>
|          | $0\%$ | $1\%$ | $3\%$ | $6\%$ | $12\%$ | $25\%$ | $50\%$ | $100\%$ |
|:--------:|-------|:-----:|:-----:|:-----:|--------|--------|--------|---------|
| $\sigma$ | 0     |   10  |   30  |   60  | 120    | 250    | 500    | 1000    |
</center>

It is important to note that at $\sigma = 0$ there is no pressure to be genetically different.
This is similar to running a standard tournament selection.
Looking at the other extreme, at $\sigma = 1000$ there is constant pressure to be genetically different.
These parameter estimates allow us to effectivly explore the range between these extremes.

## Novelty Search

This algorithm asks us to define two variables: distance function for two candidate solution performances and number of nearest neighbors.
The method in which candidate solutions are selected as parents will be through a tournament selection with tournament size $t^*$.
Let $dist(x,y)$ be the function that measures the distance between two candidate solution performances.
This function can be defined by,

<center>
$$dist(x,y) = || x - y ||_2$$
</center>

Let $k \in \mathbb{Z}^+$ be the $k-$nearest neighbors.
We wanted to explore the parameters around $k=15$ because of its use in [8].
These parameter were estimated keeping $k=15$ in mind to explore the region around it.
This give us the parameter estimates,

<center>
|     | $0\%$ | $\approx1\%$ | $\approx3\%$ | $\approx6\%$ | $\approx12\%$ | $25\%$ | $50\%$ | $100\%$ |
|:---:|-------|:------------:|:------------:|:------------:|---------------|--------|--------|---------|
| $k$ | 0     |       1      |       2      |       4      | 8             | 15     | 30     | 60      |
</center>

It is important to note that at $k = 0$ there is no pressure for solutions to increase their distance from neighboors on the fitness landscape.
This is similar to running a standard tournament selection.
Looking at the other extreme, at $k = 60$ there is constant pressure to move away from the $60$ nearest neighbors within the fitness landscape per candidate solution.


## $\epsilon$-Lexicase

The only variable this algorithm asks us to define is the threshold to pass through filters.
For this experiment we look at the maximum threshold used in [9], which is $\epsilon = 10.0$.
We would like to explore the region between the smallest possible $\epsilon$ and the maximum $\epsilon$ value from [9].
This give us the parameter estimates,

<center>
|            | $0\%$ | $1\%$ | $3\%$ | $6\%$ | $12\%$ | $25\%$ | $50\%$ | $100\%$ |
|:----------:|-------|:-----:|:-----:|:-----:|--------|--------|--------|---------|
| $\epsilon$ | 0     |  0.1  |  0.3  |  0.6  | 1.2    | 2.5    | 5.0    | 10.0    |
</center>

It is importrant to note that $\epsilon = 0$ gives us the original lexicase selection. 

## Age-Layered Population Structure (ALPS)

TBD

# Diagnostics

TODO - Describes the set up for for diagnostics. Follow simialr flow to selection depth and experiement set up

TODO - Create diagnostic depth


# Data Gathering & Metrics

Before discussing the statistics being gathered we must define some variables.
Let $\tau$ be a threshold for distance between a trait and its cooresponding target objective.
The current population of candidate solutions is given by $P$.
A candidate solution's trait perforamce will be called fitness.
The set of fitnesses for a candidate solution will be denoted by $F = \{f_1,...,f_m\}$. 
Each fitness value cooresponds to a traits' performance by position, or $f_i \leftrightarrow t_i$. 

Traits are considered optimimal if the distance from the trait to the cooresponding target objective is less than $\tau$.
Let $t \in \mathbb{R}$ be some trait, $\gamma \in \mathbb{R}$ be the cooresponding target objective, and the function $op$ determine optimality. 
The function $op$ is described by, 
$$
op(t, \gamma) = \left\{
        \begin{array}{ll}
            1 & \quad \text{if } | t - \gamma | \leq \tau\\
            0 & \quad \text{otherwise}
        \end{array}
    \right.
$$


A candidate solution is considered optimal if all of its traits are optimal.
From this definition we derive the following definition.

Let $j = \{t_1, ..., t_M \}$ be a candidate solution from $P$, where $j \in \mathbb{R}^M$.
If $j$ is an optimal solution for some set of target objectives $\Gamma = \{\gamma_1, ..., \gamma_M \}$, then 
$$ M = \sum_{i = 1}^{M} op(t_i, \gamma_i)$$

We would like to note that different values of $\tau$ will be explored to find interesting results. 


## Performance Metrics

Below we describe the data we are tracking at different levels that give us insight on performance.

### Individual Candidate Solution Metrics

These metrics are data we are collecting at the individual level. 

#### Number of Optimized Traits

To obtain the number of optimized traits for a candidate soultion, we must go through every trait and determine its optimality.
After doing this, we can count the number of optimized traits.

Let $c_j$ denote the number of optimized traits for candidate solution $j= \{t_1, ..., t_M \}$, where $c_j \in \mathbb{N}$.
For some given set of target objectives $\Gamma = \{ \gamma_1, ..., \gamma_M \}$, the number of optimized traits for $j$ is given by

$$c_j = \sum_{i = 1}^{M} op(t_i, \gamma_i) $$


#### Fitness Aggregate and Average Trait Fitness

All diagnostics can be thought of as maximization problems with different constraits applied.
Each diagnotic will measure trait performance differently, giving us different performances for the same candidate solution.
We will let $\omega$ denote the aggregate of fitnesses for a candidate solution. 

For candidate solution $j$, let $F_j = \{f_1, ..., f_m \}$ represent its fitness vector, where $F_j \in \mathbb{R}^M$. 
Now let $\omega_j$ denote the aggregate of fitnesses for a candidate solution $j$.
We define $\omega_j$ by, 
$$ \omega_j = \sum_{f \in F_j} f$$

In order to calculate the average trait fitness we do the following, 

$${\bar{\omega_j}} = \frac{\omega_j}{M} =  \frac{1}{M} \sum_{f \in F_j} f$$


### Population Metrics Across All Candidate Solutions

These metrics calculated across all candidate solutions in the population.
Let $P_{F}$ be the set of aggregate fitnesses and $P_{C}$ be the set of optimized traits counts, both per candidate solution in the population $P$.

#### Average Number of Optimized Traits

The average number of optimized traits is calculated by summing up every candidate solutions' optimized trait count, followed by dividing the sum by the size of the population.
This data gives us insight on the average number of traits a candidate solution in the population can maintain optimized. 
Now let $C_P$ represent the average number of optimized traits. 

We define $C_P$ by, 
$$C_P = \frac{1}{N} \sum_{c \in P_C} c$$


#### Maximum Number of Optimized Traits

We go through every candidate solutions' optimized trait count and record the maximum.
Now let $C_{max}$ represent the maximum optimized trait count. 

We define $C_{max}$ by, 
$$C_{max} = max\{P_C \}$$

#### Number of Unique Optimized Traits

We go through each target objective in $\Gamma$, and see if there exists a candidate solution that has the the corresponding trait optimized.
This will tell us the the spread of optimized traits that a population can maintain. 
Now let $C_{uni}$ represent the number of unique optimized traits. 

For some set of target objectives $\Gamma = \{\gamma_1, ..., \gamma_M\}$, we define $C_{uni}$ by,
$$C_{uni} = \sum_{i = 1}^{M} OP(\gamma_i)$$
Where the function $OP$ measures whether or not a candidate solution exists with an optimized trait for the corresponding target objective.
We define $OP$ by, 
$$
OP(\gamma_i) = \left\{
        \begin{array}{ll}
            1 & \quad \text{if there exists a solution with trait } t_i \text{, where } op(t_i, \gamma_i) = 1\\
            0 & \quad \text{otherwise}
        \end{array}
    \right.
$$

#### Average Aggregate Trait Performance

We sum every candidate solution aggregate fitness value $\omega$, followed by dividing the sum by the size of the population. 
Now let $\bar{f_{P}}$ represent the average aggregate fitness per candidate solution. 

We define $\bar{f_{P}}$ by, 
$$\bar{f_{P}} = \frac{1}{N} \sum_{f \in P_F} f$$

#### Optimal Solutions Found Per Generation

We record the the number of optimal solutions per generation. 

### Candidate Solutions of Interest

Below we describe different kinds of candidate solutions we are interested in analyzing.

#### Maximum Performing Candidate Solution

This candidate solution is selected because their aggregate fitness value $\omega = max\{P_F\}$.
In the event of a tie we select the candidate solution with the most optimized traits. 
If ties still occur, we randomly select a candidate solution.
Below is a list of data we are gathering for these kinds of solutions. 

- [Number of Optimized Traits](#number-of-optimized-traits)
- [Fitness Aggregate and Average Trait Fitness](#fitness-aggregate-and-average-trait-fitness)

#### Maximum Optimized Trait Count

This candidate solution is selected because their aggregate fitness value $c = C_{max}$.
In the event of a tie we select the candidate solution with the maximum aggregate fitness value. 
If ties still occur, we randomly select a candidate solution.
Below is a list of data we are gathering for these kinds of solutions. 

- [Number of Optimized Traits](#number-of-optimized-traits)
- [Fitness Aggregate and Average Trait Fitness](#fitness-aggregate-and-average-trait-fitness)

#### Most Common Candidate Solution

This candidate solution is selection because it is the most common solution in the population.
In the event of ties, we first filter solutions by the maximum aggregate fitness value, then by maximum number of optimized traits.
If ties still occur, we randonly select a candidate solution. 
Below is a list of data we are gathering for these kinds of solutions. 

- [Number of Optimized Traits](#number-of-optimized-traits)
- [Fitness Aggregate and Average Trait Fitness](#fitness-aggregate-and-average-trait-fitness)


## Diversity Metrics

These metrics are all population based as well, but with a focus on diversity.
Let $\Pi$ be the set of candidate solutions selected to produce an offspring.
We want to note that $\Pi$ consists of candidate solutions from population $P$.
Also, let $P_F$ be the set of aggregate fitnesses per candidate solution in the population P.


### Systematics Tracker Data

I need to look into the kinds of data that the systematic tracker can record. 
I know that it does phylogenies, but need to do more looking into. 

### Loss in diversity

The loss in diversity can be measured by dividing the number of unique candidate solutions selected to produce an offspring by the size of the population. 
Per selection event, this will tell us the the proportion of diversity that is lost and how inclusive the algorithm is. 
Loss in diversity can now be defined by, 

$$ \frac{unique(\Pi)}{N}$$

### Selection Pressure

According to the authors in [5], the change of the average fitness of the population due to selection is a reasonable measure for selection intensity.
Let $\bar{f_P}$ be the average and $s_P$ be the standard deviation of the set of all aggregate fitnesses $P_F$.
Also let $\bar{f_\Pi}$ measure a value similar to $\bar{f_P}$, but with respect to $\Pi$.
Selection pressure can now be defined by, 
$$\frac{\bar{f_{\Pi}} - \bar{f_{P}}}{s_{P}}$$

### Selection Variance

The authors in [5] also define a measurement for selection variance. 
Before we define this, let $\Pi_F$ denote the set of aggregate fitnesses for candidate solutions in $\Pi$. 
Now let $s_P$ be the standard deviation for $P_F$ and $s_{\Pi}$ be the standard deviation for $\Pi_F$.
Selection variance can now be defined by, 
$$\frac{s_P^2}{s_{\Pi}^2}$$

**Both selection pressure and variance are taken at every generation**



# Citations
1. Hornby, Greg & Globus, Al & Linden, Derek & Lohn, Jason. (2006). Automated Antenna Design with Evolutionary Algorithms. Collection of Technical Papers - Space 2006 Conference. 1. 10.2514/6.2006-7242.
2. K. Deb, A. Pratap, S. Agarwal and T. Meyarivan, "A fast and elitist multiobjective genetic algorithm: NSGA-II," in IEEE Transactions on Evolutionary Computation, vol. 6, no. 2, pp. 182-197, April 2002.
3. Akyazı U., Uyar A.Ş. (2010) Detection of DDoS Attacks via an Artificial Immune System-Inspired Multiobjective Evolutionary Algorithm. In: Di Chio C. et al. (eds) Applications of Evolutionary Computation. EvoApplications 2010. Lecture Notes in Computer Science, vol 6025. Springer, Berlin, Heidelberg
4. P. Guturu and R. Dantu, "An Impatient Evolutionary Algorithm With Probabilistic Tabu Search for Unified Solution of Some NP-Hard Problems in Graph and Set Theory via Clique Finding," in IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics), vol. 38, no. 3, pp. 645-666, June 2008.
5. T. Blickle and L. Thiele, "A Comparison of Selection Schemes Used in Evolutionary Algorithms," in Evolutionary Computation, vol. 4, no. 4, pp. 361-394, Dec. 1996.
6. Sean Luke, 2013, Essentials of Metaheuristics, Lulu, second edition, available for free at http://cs.gmu.edu/~sean/book/metaheuristics/
7. B. Sareni and L. Krahenbuhl, "Fitness sharing and niching methods revisited," in IEEE Transactions on Evolutionary Computation, vol. 2, no. 3, pp. 97-106, Sept. 1998.
8. Lehman, Joel & Stanley, Kenneth. (2008). Exploiting open-endedness to solve problems through the search for novelty. Artificial Life - ALIFE.
9. La Cava, William, Lee Spector, and Kourosh Danai. “Epsilon-Lexicase Selection for Regression.” Proceedings of the 2016 on Genetic and Evolutionary Computation Conference - GECCO  ’16 (2016): n. pag. Crossref. Web.
10. Hornby, Greg. (2006). ALPS: The age-layered population structure for reducing the problem of premature convergence. GECCO 2006 - Genetic and Evolutionary Computation Conference. 1. 10.1145/1143997.1144142.
11. Anikó Ekárt and Sandor Z. Németh. 2000. A Metric for Genetic Programs and Fitness Sharing. In Proceedings of the European Conference on Genetic Programming. Springer-Verlag, Berlin, Heidelberg, 259–270.