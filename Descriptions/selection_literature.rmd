---
title: "Selection Scheme Diagnostics: Selection Scheme Literature"
author: "[Jose Guadalupe Hernandez](https://www.google.com/)"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    self_contained: true
    thumbnails: true
    lightbox: true
    gallery: false
    highlight: "kate"
    use_bookdown: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Evolutionary Algorithms

Evolutionary algorithms are a set of algorithms used to solve complex optimization problems through an evolutionary process.
These algorithms take inspiration from nature and follow a similar evolutionary process.
This evolution process was able to evolve single cellular organisms to the complex life we see today.
These algorithms present a promising approach for solving complex optimization problems and problems that are difficult to represent in a mathematical equation. 

Notable contributions evolutionary algorithms have made can be found in [1,2,3,4].
Benefits of using evolutionary algorithms include,

- No problem space assumptions required
- Discover alternative solutions unintuitive to a human designer 
- Provide an alternative approach when no clean mathematical model exists for problem

Different variables, conditional, and procedures must be determined prior to running an evolutionary algorithm.
Examples of these requirements are

- Candidate solution underlying representation
- Stopping criterion
- Mutation operators and rates of mutation
- Selection scheme

Once all required variables, conditionals, and procedures are determined, evolutionary algorithms generally follow the following steps.

1. Generate population zero
2. Evaluate candidate solutions fitness
3. Check stopping criterion
4. selection scheme 
5. Mutation operators
6. Form next generation
7. Repeat steps 2 - 6

The primary focus of this literature review is on **selection schemes**.


# Selection Schemes 

Below is a description and analysis of the different selection schemes used in this project.

## (μ,λ) Selection

### Description

This selection scheme requires a population size $\lambda$ and candidate solution count $\mu$.
The solution count $\mu$ denotes the size of a new subset that consists of the $\mu$ solutions with the highest fitness.
Fitness in this selection scheme is the aggregate performance across all test cases.
A process must also be determined to handle ties in fitness when forming the new subset.

Candidate solutions must be selected as genetic material for the following generation from this newly formed subset.
This selection scheme does not specify a process to accomplish this, and instead leaves it up to the user.
The implementation of this selection scheme from [1] has each of the $\mu$ candidate solutions produce $\frac{\lambda}{\mu}$ offspring.
Another process that could be used is running tournament selection on the new subset until enough candidate solutions are selected. 

### Algorithm

1. Form a subset of top performing $\mu$ candidate solutions from entire population
2. Select a candidate solution to be used as genetic material for the following generation from the subset
    * Each one of the $\mu$ candidate solutions creates $\frac{\lambda}{\mu}$ offspring [1]
    * Run tournament selection on the new subset
    * Infinite possibilities
3. Repeat step 2 until sufficient candidate solutions are selected

### Analysis

*I believe* the novelty this selection scheme possesses is that it only considers a subset of the top $\mu$ candidate solutions as genetic material for the following generation. 
The user is given flexibility on how to select candidate solutions for the following generation from this subset.
Both of these factors play a huge role in a selection schemes performance. 

It is worth highlighting the impact that $\mu$ has on the exploration and exploitation dynamic.
As $\mu \longrightarrow 0$, the scheme increases its focus on exploiting promising regions in fitness landscape where the population is. 
As $\mu \longrightarrow \lambda$, the scheme increases its focus on exploring the fitness landscape.
  
## Tournament Selection

### Description

This selection scheme requires a size $t$ for tournaments that consist of competitions between randomly selected candidate solutions from the population.
The candidate solution that wins a tournament is the one with the highest fitness when compared to other solutions in the tournament.
A process must also be determined to handle ties in fitness, where fitness in this selection scheme is the aggregate performance across all test cases. 

Every tournament returns a single candidate solution that will produce an offspring for the following generation.
This means that the size of the population determines the number of tournaments that need to be ran.

### Algorithm

1. Randomly select $t$ candidate solutions from the entire population (with or without replacement)
2. Select candidate solution with highest fitness to be used as genetic material for the following generation
3. Repeat steps 1-2 until sufficient candidate solutions are selected

### Analysis

*I believe* the novelty this selection scheme possesses is the manner in which candidate solutions are selected to be used as genetic material for the following generation.

It is worth highlighting the impact that $t$ has on the exploration and exploitation dynamic.
As $t \longrightarrow N$, the scheme increases its focus on exploring the fitness landscape. 
As $t \longrightarrow 0$, the scheme increases its focus on exploiting promising regions in fitness landscape where the population is. 

## Fitness Sharing 

### Description

Fitness sharing requires multiple parameters and functions to be defined prior to running.
Let $f_i$ be the original fitness value and $f'_i$ be the transformed fitness value for candidate solution $i$. 
The transformation from $f_i$ to $f'_i$ is given by the following formula, 

<center>
$f'_i = \frac{f_i}{m_i}$
</center>

Let $m_i$ be the niche count which measures the approximate number of candidate solutions with whom the fitness $f_i$ is shared [2].
Niche count is calculated by summing a sharing function over all candidate solutions [2].
The sharing function can be applied to either genotypic or phenotypic candidate solution properties.  

The following formula describes $m_i$,

<center>
$$m_i = \sum_{j=1}^{N} sh(d_{ij})$$
</center>

Let the function $sh()$ measure the similarity between two candidate solutions and $d_{ij}$ measure the distance between candidate solutions $i$ and $j$. 

The following formula describes the function $sh$,

<center>
$$
sh(d_{ij}) = \left\{
        \begin{array}{ll}
            1 - (\frac{d_{ij}}{\sigma})^{\alpha} & \quad \text{if } d_{ij} < \sigma\\
            0 & \quad \text{otherwise}
        \end{array}
    \right.
$$
</center>

Let $\alpha,\sigma \in \mathbb{R}$. 
The variable $\alpha$ acts as a parameter that regulates the shape of the sharing function and $\sigma$ acts as a threshold for dissimilarity. 

Candidate solutions must be selected as genetic material for the following generation from the population, post fitness transformation.
This selection scheme does not specify a process to accomplish this, and instead leaves it up to the user.
An exmple of this process could running tournament selection until enough candidate solutions are selected. 

### Algorithm

1. Compute the distance matrix for genotypic or phenotypic properties
2. Transform all original fitness values $f$ to transformed fitness values $f'$
3. Select a candidate solution to act as a parent for the next generation 
    * Tournament selection
    * Lexicase filtering
    * Infinite possibilities
4. Repeat step 3 until sufficient candidate solutions are selected  

### Analysis

*I believe* the novelty this selection scheme possesses is its modification of the original fitness value. 
This algorithm punishes candidate solutions for being close to other solutions within the space of all genotypes or phenotypes.
The user is given flexibility on how to select candidate solutions for the following generation.

The extreme cases for distance between candidate solutions $d_{ij}$ can give us a better understanding of what this value represents. 
As $d_{ij} \longrightarrow \infty$, the distance between two solutions in the space of all genotypes or phenotypes is growing. 
As $d_{ij} \longrightarrow 0$, there is practically no distance between two solutions in the space of all genotypes or phenotypes.

A candidate solution is penalized if its distance to another solution falls below the threshold $\sigma$. 
The threshold value $\sigma$ can be viewed as a nob for determining the pressure candidate solutions face to be distant from one another. 
This solution scheme pushes candidate solutions to be at least $\sigma$ apart within the space of all genotypes or phenotypes.
As $\sigma \longrightarrow 0$ there is no little to no fitness modification occurring. 
As $\sigma \longrightarrow max(d_{ij})$ there is extreme pressure for the whole population to be spread across the landscape.
The penalty is increased as $\alpha \longrightarrow \infty$ and decreases as $\alpha \longrightarrow 0$.

It is important to note that if a candidate solution is at least $\sigma$ apart from all other solutions, then it will not undergo a fitness transformation.

## Novelty Search

### Description

This selection scheme searches with no objective in consideration, other than continually finding novel behaviors in the space of all possible phenotypes.
A count and function measuring the distance between two candidate solutions must be defined. 
Let $k$ be the count for the $k-$nearest neighbors and $dist(i,j)$ be a function that measures the distance between candidate solutions $i$ and $j$.
The original fitness value for candidate solution $x$ will be defined by $f_x$, and the transformed fitness value by $f'_x$.

The transformation from $f_x$ to $f_x'$ is given by, 

<center>
$$f_x'  = \frac{1}{k} \sum_{i=0}^{k} dist(f_x, \mu_i)$$
</center>

where $\mu_i$ is the original fitness value for one of the $k-$nearest neighbors. 

Candidate solutions must be selected as genetic material for the following generation from the population, post fitness transformation.
This selection scheme does not specify a process to accomplish this, and instead leaves it up to the user.
An example of this process could be running tournament selection until enough candidate solutions are selected. 

### Algorithm

1. Transform original fitness values to novelty fitness values
2. Select individual candidate solutions to use as parent for the next generation 
    * Tournament selection
    * Infinite possibilities
3. Repeat step 2 until enough candidate solutions selected

### Analysis

*I believe* the novelty this selection scheme possesses is the constant pressure it puts on candidates’ solutions to produce novel behaviors different from the $k-$nearest neighbors. 
This selection scheme also specifies that only values from the space of all possible phenotypes are allowed to be transformed.
Looking at the extreme cases for $k$ can give a better understanding of its impact.

Let $N$ be the size of the population. 
As $k \longrightarrow 1$, the selection scheme applies more pressure on candidate solutions to spread apart from their nearest neighbor. 
As $k \longrightarrow N$, the selection scheme applies more pressure for candidate solutions to spread apart from all other solutions. 
This puts pressure on candidate solutions to produce novel behaviors.

## ϵ-Lexicase

### Description

This selection scheme uses performances on individual testcases to reduce the number of solutions to a single solution to use as genetic material for the following generation.
Candidate solutions in this scheme possess a set of fitnesses, rather than an aggregate value across all individual testcase performances. 
These testcases are shuffled and then used as filters to trim down the number of solutions by taking the top performing solutions on the current testcase. 
The next testcase is used until a single candidate solution remains or no more testcases remain.
Top performing candidate solutions that pass a filter possess high fitness values for a given testcase.
The distribution of fitness values depends on a threshold $\epsilon$, where this threshold allows different solutions to pass through a filter. 

Candidate solutions that satisfy the following are allowed to pass through the filters previously described. 
Let $e^{*}_{i}$ be the best fitness on testcase $i$ from candidate solution $*$.
Any candidate solution $j$, where $j \ne *$, from the population that meets the following criteria passes through the lexicase filters

<center>
$$| e^*_i - e_i^j | \le \epsilon $$
</center>

### Algorithm

1. Shuffle testcase order
2. Filter down set of candidate solutions with individual testcases until a solution is found to use as a parent for the next generation. 
3. Repeat steps 1-2 until enough candidate solutions selected

### Analysis

*I believe* this selection scheme possesses two novelties: keeping testcase performance independent and using testcases to filter through candidate solutions.
This incentivizes the population to perform well on different testcases to pass through filters and the following generation.
Other selection schemes typically aggregate the performance across all testcases.


## Age-Layered Population Structure (ALPS)

### Description

This selection scheme presents a population structure where interactions between different candidate solutions is dependent on age.
Interaction in this context refers to the possibility of candidate solutions competing against one another.
The population is divided into cohorts, where a candidate solutions' assignments are dependent on its age. 
Candidate solutions are only allowed to interact with solutions that belong to the same cohort. 

A variable measuring the age gap $\alpha$ and number of cohorts $C$ must be determined before being ran. 
There are different methods for constructing different age gaps that can be explored in [5].
The age of a candidate solution is dependent on the number of generations it has persisted. 
An offspring’s' age is the age of its parent incremented by 1.

This means that after every $\alpha$ generations, solutions are moving to the next cohort.
The first cohort is populated with random candidate solutions after $\alpha$ generations.
The final cohort has no age limit and only best performing candidate solutions are kept. 

### Algorithm

1. Place candidate solutions into appropriate cohorts
2. Select individual candidate solutions to use as parents for the next generation, per individual cohort
    * Tournament selection
    * Lexicase filtering
    * Infinite possibilities
3. Repeat steps 1 - 2 until sufficient parents selected

### Analysis

*I believe* the novelties this selection scheme possesses is the age based population structure and injection of random candidate solutions.
There is the potential to remove older, struggling candidate solution because of this structure.
Younger candidate solutions are now given the protection to develop and compete with older solutions.
The ability to inject new random candidate solutions allows the population to explore different regions of the genotype and phenotype space. 

The age gap gives candidate solutions $\alpha$ generations to improve their performance before proceeding to the next cohort. 
Age can be viewed as a knob for the amount of generations candidate solutions have to develop before facing older, potentially better solutions. 
As $\alpha \longrightarrow 1$ there exists almost no protection for younger solutions against older ones. 
As $\alpha \longrightarrow \infty$ younger organisms gain more time to develop. 
It should also be noted that if $\alpha$ is bigger than the number of generations possible, the age based population structure no longer exists.


## Citations
1. Sean Luke, 2013, Essentials of Metaheuristics, Lulu, second edition, available for free at http://cs.gmu.edu/~sean/book/metaheuristics/ 
2. B. Sareni and L. Krahenbuhl, "Fitness sharing and niching methods revisited," in IEEE Transactions on Evolutionary Computation, vol. 2, no. 3, pp. 97-106, Sept. 1998.
3. Lehman, Joel & Stanley, Kenneth. (2008). Exploiting open-endedness to solve problems through the search for novelty. Artificial Life - ALIFE. 
4. La Cava, William, Lee Spector, and Kourosh Danai. “Epsilon-Lexicase Selection for Regression.” Proceedings of the 2016 on Genetic and Evolutionary Computation Conference - GECCO  ’16 (2016): n. pag. Crossref. Web.
5. Hornby, Greg. (2006). ALPS: The age-layered population structure for reducing the problem of premature convergence. GECCO 2006 - Genetic and Evolutionary Computation Conference. 1. 10.1145/1143997.1144142. 